# Artificial Intelligence Study

|Topics|Description|
|-|-|
|[Stanford Alpaca Study Note](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Stanford%20Alpaca%20Study%20Note.md)|By studying this practical example to gain a deeper understanding of artificial intelligence and large language models.|
|[Get to know Instruction Dataset](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Get%20to%20know%20Instruction%20Dataset.md#get-to-know-instruction-dataset)|Use an existing dataset and convert it into an instruction dataset. Started with an existing dataset (the Alpaca dataset from Hugging Face). Download and save this dataset using the Hugging Face datasets library. Load this saved dataset and convert it into a single JSON file with a specific format which is essentially an instruction-output format.|
|[Get to know Dataset in Parquet Files](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Get%20to%20know%20Dataset%20in%20Parquet%20Files.md)|Understanding Dataset techniques helps in better utilizing the training data and fine-tuning your language models for specific applications.|
|[Get to know GGUF Files](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Get%20to%20know%20GGUF%20Files.md)|GGUF stands for GPT-Generated Unified Format, which is a file format used for storing large language models, particularly those based on the GPT (Generative Pre-trained Transformer) architecture.|
|[LLMOps](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/LLMOps.md#llmops)|As teams deploy large language models to production, the same challenges around performance and task measurement still exist. Hence, LLMOps is essential to scale large language models and deploy them to production effectively.|
|[LLM Roadmap](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/LLM%20Roadmap.md)|Dr. Maxime Labonne: The LLM course is divided into three parts.<br>LLM Fundamentals covers essential knowledge about mathematics, Python, and neural networks.<br> The LLM Scientist focuses on building the best possible LLMs using the latest techniques.<br>The LLM Engineer focuses on creating LLM-based applications and deploying them.|

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

Made with ❤️ by [Allen Sun](https://github.com/allenintaipei)
