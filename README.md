# Artificial Intelligence Study

|Topics|Description|
|-|-|
|[Stanford Alpaca Study Note](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Stanford%20Alpaca%20Study%20Note.md)|By studying this practical example to gain a deeper understanding of artificial intelligence and large language models.|
|[Get to know Instruction Dataset](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Get%20to%20know%20Instruction%20Dataset.md#get-to-know-instruction-dataset)|Use an existing dataset and convert it into an instruction dataset. Started with an existing dataset (the Alpaca dataset from Hugging Face). Download and save this dataset using the Hugging Face datasets library. Load this saved dataset and convert it into a single JSON file with a specific format which is essentially an instruction-output format.|
|[Get to know Dataset in Parquet Files](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Get%20to%20know%20Dataset%20in%20Parquet%20Files.md)|Understanding Dataset techniques helps in better utilizing the training data and fine-tuning your language models for specific applications.|
|[Get to know GGUF Files](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Get%20to%20know%20GGUF%20Files.md)|GGUF stands for GPT-Generated Unified Format, which is a file format used for storing large language models, particularly those based on the GPT (Generative Pre-trained Transformer) architecture.|
|[LLMOps](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/LLMOps.md#llmops)|As teams deploy large language models to production, the same challenges around performance and task measurement still exist. Hence, LLMOps is essential to scale large language models and deploy them to production effectively.|
|[How to Productionize Large Language Models](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/How%20to%20Productionize%20Large%20Language%20Models.md)|LLM ops is not easy.|
|[LLM Roadmap](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/LLM%20Roadmap.md)|Dr. Maxime Labonne: The LLM course is divided into three parts.<br>LLM Fundamentals covers essential knowledge about mathematics, Python, and neural networks.<br> The LLM Scientist focuses on building the best possible LLMs using the latest techniques.<br>The LLM Engineer focuses on creating LLM-based applications and deploying them.|
|[Generate and Use Synthetic Data for Finetuning](https://github.com/AlleninTaipei/Artificial-Intelligence-Study/blob/main/Generate%20and%20Use%20Synthetic%20Data%20for%20Finetuning.md)|The process of collecting and annotating data is both time-consuming and expensive, leading to several challenges.|

## The following are highly valuable video links that are worth exploring in depth.

|Topics|Description|
|-|-|
|[Meta's Roadmap for Full Stack AI: Insights from Joe Spisak](https://www.youtube.com/watch?v=QS7C3ZCI8Dw&t=180s&pp=ygUMbWV0YSByb2FkbWFw)|Ray Summit is the conference for builders creating the AI future. Ray Summit brings together software engineers, machine learning practitioners, data scientists, developers, MLOps professionals, and architects — and anyone else who wants to learn about building, productionizing and deploying large-scale applications, especially in AI and machine learning. The summit brings the global Ray community together to learn the fundamentals, explore new use cases, share best practices, and discuss the future of AI.<br>Generative AI has brought about a new wave of innovation unlike we’ve ever seen before and with hundreds of millions of downloads of Llama models to date, the startup ecosystem building on Llama and this new wave of innovation fueled by open models. But where does all of this go? Joe Spisak, Product Director at Meta talks about how open generative AI has had incredible impact and how you can leverage the Llama ecosystem to build cutting edge generative AI agents at scale using a full stack of components including hands-on, engaging content that gives attendees an understanding of the latest Llama models, how to access and use them, develop using system level safety components and ultimately what the future may look like.|

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

Made with ❤️ by [Allen Sun](https://github.com/allenintaipei)
